{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import *\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kafka import KafkaConsumer, KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#   Transformers\n",
    "class ColumnRenamer(Estimator, Transformer):\n",
    "    def __init__(self, columnsNameOld = \"\", columnsNameNew = \"\"):\n",
    "        self.columnsNameOld = columnsNameOld\n",
    "        self.columnsNameNew = columnsNameNew\n",
    "    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.withColumnRenamed(self.columnsNameOld, self.columnsNameNew)\n",
    "\n",
    "class ColumnDropper(Estimator, Transformer):\n",
    "    def __init__(self, columnsName = [\"id_region\"]):\n",
    "        self.columnsName = columnsName\n",
    "    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        for g in self.columnsName:\n",
    "            Xaux = Xaux.drop(g)\n",
    "        return Xaux\n",
    "\n",
    "class ColumnTransformer(Estimator, Transformer):\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        Xaux = Xaux.withColumn('object_type', \n",
    "            when(Xaux.object_type.endswith('2'),regexp_replace(Xaux.object_type,'2','1')) \\\n",
    "            .otherwise(Xaux.object_type))\n",
    "        Xaux = Xaux.withColumn('rooms', \n",
    "            when(Xaux.rooms.endswith('-1'),regexp_replace(Xaux.rooms,'-1','0')) \\\n",
    "            .otherwise(Xaux.rooms))\n",
    "        Xaux = Xaux.withColumn('kitchen_area', \n",
    "            when(Xaux.kitchen_area == '-100.0',regexp_replace(Xaux.kitchen_area,'-100','0')) \\\n",
    "            .otherwise(Xaux.kitchen_area))\n",
    "        # Xaux = Xaux.withColumn('object_type',Xaux.object_type.cast(IntegerType()))\n",
    "        Xaux = Xaux.withColumn('object_type',Xaux.object_type.cast(BooleanType()))\n",
    "        Xaux = Xaux.withColumn('rooms',Xaux.rooms.cast(IntegerType()))\n",
    "        Xaux = Xaux.withColumn('kitchen_area',Xaux.kitchen_area.cast(FloatType()))\n",
    "        return Xaux\n",
    "\n",
    "class RecoveryDataTransformer(Estimator,Transformer):\n",
    "    def __init__(self, columnsName = [\"\"]):\n",
    "        self.columnsName = columnsName\n",
    "\n",
    "    def find_median(self, values_list) -> float:\n",
    "        result_median = np.nanmedian(np.array(values_list, dtype=float))\n",
    "        return float(result_median)\n",
    "\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "\n",
    "        if len(self.columnsName) > 0:\n",
    "            for field in self.columnsName:\n",
    "                Xaux_list = Xaux.select(field).collect()\n",
    "                Xaux_array = [int(row[field]) for row in Xaux_list]\n",
    "                median_result = self.find_median(Xaux_array)\n",
    "                Xaux.fillna(value=median_result, subset=field)\n",
    "\n",
    "        return Xaux\n",
    "\n",
    "class LineDistincter(Estimator, Transformer):    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.distinct()\n",
    "\n",
    "class LineDropper(Estimator, Transformer):\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.na.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "####################### Train model #######################\n",
    "hdfsurl=\"hdfs://10.84.128.47:9000\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"House Prices\") \\\n",
    "        .getOrCreate()\n",
    "df = spark.read.load(hdfsurl + \"/grupo8/input_data_1000_lines.csv\",format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "df = df.withColumn(\"price\",df.price.cast(DoubleType()))\n",
    "df.head()\n",
    "\n",
    "### Limpeza\n",
    "to_encode_col_names = ['price','level','levels','rooms','area','kitchen_area','building_type','object_type','id_region']\n",
    "to_remove_col_names = ['date','house_id','postal_code','geo_lat','geo_lon'] # ,'street_id'\n",
    "to_recover_col_names = ['price','level','levels','rooms','area','kitchen_area','building_type']\n",
    "\n",
    "df_clean = Pipeline(stages=[ColumnDropper(to_remove_col_names), RecoveryDataTransformer(to_recover_col_names), LineDistincter(), LineDropper(), ColumnTransformer()]).fit(df).transform(df)\n",
    "\n",
    "data = df_clean.toPandas()\n",
    "\n",
    "y=data.iloc[:,0]\n",
    "data=data.drop('price', axis=1)\n",
    "x=data.iloc[:, 0:9]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "model = linear_model.Ridge(alpha = 300)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    data.drop('id', axis=1, inplace=True)\n",
    "    data.drop('price', axis=1, inplace=True)\n",
    "    data.drop('date', axis=1, inplace=True)\n",
    "    data.drop('house_id', axis=1, inplace=True)\n",
    "    data.drop('postal_code', axis=1, inplace=True)\n",
    "    data.drop('geo_lat', axis=1, inplace=True)\n",
    "    data.drop('geo_lon', axis=1, inplace=True)\n",
    "\n",
    "    # print(data.dtypes)\n",
    "    data[\"object_type\"].replace({2:1}, inplace=True)\n",
    "    data[\"rooms\"].replace({-1:0}, inplace=True)\n",
    "    data[\"kitchen_area\"].replace({-100:0}, inplace=True)\n",
    "\n",
    "# Kafka Consumer (Topic: streaming-bd)\n",
    "consumer = KafkaConsumer(\n",
    "    'streaming-views-input',\n",
    "    bootstrap_servers='172.25.24.45:9092',\n",
    "    auto_offset_reset='earliest'\n",
    ")\n",
    "\n",
    "def serializer(message):\n",
    "    return json.dumps(message).encode('utf-8')\n",
    "\n",
    "# Kafka Producer (Topic: streaming-feedback)\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='172.25.24.45:9092',\n",
    "    value_serializer=serializer\n",
    ")\n",
    "\n",
    "## Kafka loop\n",
    "for message in consumer:\n",
    "    streaming_data = json.loads(message.value)\n",
    "    data_normalized = pd.json_normalize(json.loads(message.value))\n",
    "    new_data = pd.DataFrame.from_dict(data_normalized)\n",
    "\n",
    "    if 'id' in new_data.columns: \n",
    "\n",
    "        #################### New data predition\n",
    "        id = new_data.iloc[:,0].to_string(index=False)\n",
    "        atual_price = new_data.iloc[:,2].to_string(index=False)\n",
    "\n",
    "        cleanData(new_data)\n",
    "\n",
    "        predPrice = model.predict(new_data)\n",
    "\n",
    "        message = 'ID: ' + id\n",
    "        print(id)\n",
    "        \n",
    "        pred = predPrice[0].round(1)\n",
    "        if float(pred) > float(atual_price):\n",
    "            message += ' has a Good Price!'\n",
    "        else: \n",
    "            message += ' has a Bad Price!'\n",
    "        \n",
    "        message += ' House price: ' + atual_price + ' | Predition: ' + str(np.abs(pred))\n",
    "        print(message)\n",
    "        producer.send('streaming-feedback-bd', message)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df8f8261e415d1cd982fd9b77cef1d0f03bb069bb553091b78165945112d252a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}