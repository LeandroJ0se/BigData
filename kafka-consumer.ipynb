{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import *\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "###                Transformers                 ###\n",
    "###################################################\n",
    "class ColumnRenamer(Estimator, Transformer):\n",
    "    def __init__(self, columnsNameOld = \"\", columnsNameNew = \"\"):\n",
    "        self.columnsNameOld = columnsNameOld\n",
    "        self.columnsNameNew = columnsNameNew\n",
    "    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.withColumnRenamed(self.columnsNameOld, self.columnsNameNew)\n",
    "\n",
    "class ColumnDropper(Estimator, Transformer):\n",
    "    def __init__(self, columnsName = [\"id_region\"]):\n",
    "        self.columnsName = columnsName\n",
    "    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        for g in self.columnsName:\n",
    "            Xaux = Xaux.drop(g)\n",
    "        return Xaux\n",
    "\n",
    "class ColumnTransformer(Estimator, Transformer):\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        Xaux = Xaux.withColumn('object_type', \n",
    "            when(Xaux.object_type.endswith('2'),regexp_replace(Xaux.object_type,'2','1')) \\\n",
    "            .otherwise(Xaux.object_type))\n",
    "        Xaux = Xaux.withColumn('rooms', \n",
    "            when(Xaux.rooms.endswith('-1'),regexp_replace(Xaux.rooms,'-1','0')) \\\n",
    "            .otherwise(Xaux.rooms))\n",
    "        Xaux = Xaux.withColumn('kitchen_area', \n",
    "            when(Xaux.kitchen_area == '-100.0',regexp_replace(Xaux.kitchen_area,'-100','0')) \\\n",
    "            .otherwise(Xaux.kitchen_area))\n",
    "        # Xaux = Xaux.withColumn('object_type',Xaux.object_type.cast(IntegerType()))\n",
    "        Xaux = Xaux.withColumn('object_type',Xaux.object_type.cast(BooleanType()))\n",
    "        Xaux = Xaux.withColumn('rooms',Xaux.rooms.cast(IntegerType()))\n",
    "        Xaux = Xaux.withColumn('kitchen_area',Xaux.kitchen_area.cast(FloatType()))\n",
    "        return Xaux\n",
    "\n",
    "class RecoveryDataTransformer(Estimator,Transformer):\n",
    "    def __init__(self, columnsName = [\"\"]):\n",
    "        self.columnsName = columnsName\n",
    "\n",
    "    def find_median(self, values_list) -> float:\n",
    "        result_median = np.nanmedian(np.array(values_list, dtype=float))\n",
    "        return float(result_median)\n",
    "\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "\n",
    "        if len(self.columnsName) > 0:\n",
    "            for field in self.columnsName:\n",
    "                Xaux_list = Xaux.select(field).collect()\n",
    "                Xaux_array = [int(row[field]) for row in Xaux_list]\n",
    "                median_result = self.find_median(Xaux_array)\n",
    "                Xaux.fillna(value=median_result, subset=field)\n",
    "\n",
    "        return Xaux\n",
    "\n",
    "class LineDistincter(Estimator, Transformer):    \n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.distinct()\n",
    "\n",
    "class LineDropper(Estimator, Transformer):\n",
    "    def _fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        Xaux = X\n",
    "        return Xaux.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_encode_col_names = ['price','level','levels','rooms','area','kitchen_area','object_type','building_type','id_region']\n",
    "to_remove_col_names = ['date','house_id', 'street_id', 'postal_code','geo_lat','geo_lon']\n",
    "to_recover_col_names = ['price','level','levels','rooms','area','kitchen_area','building_type']\n",
    "\n",
    "###################################################\n",
    "###                   Dataset                   ###\n",
    "###################################################\n",
    "hdfsurl=\"hdfs://10.84.128.47:9000\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"House Prices\") \\\n",
    "        .getOrCreate()\n",
    "df = spark.read.load(hdfsurl + \"/grupo8/input_data_1000_lines.csv\", format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "df = df.withColumn(\"price\", df.price.cast(DoubleType()))\n",
    "df.head()\n",
    "\n",
    "\n",
    "###################################################\n",
    "###                  Pipeline                   ###\n",
    "###################################################\n",
    "# > Stages:\n",
    "#   $ - ColumnDropper:\n",
    "#   $ - RecoveryDataTransformer:\n",
    "#   $ - LineDistincter:\n",
    "#   $ - LineDropper:\n",
    "#   $ - ColumnTransformer:\n",
    "df_clean = Pipeline(stages=[ColumnDropper(to_remove_col_names), RecoveryDataTransformer(to_recover_col_names), LineDistincter(), LineDropper(), ColumnTransformer()]).fit(df).transform(df)\n",
    "\n",
    "# Data preparation for model training\n",
    "vectorAssembler = VectorAssembler(inputCols = df_clean.drop(\"price\").columns, outputCol = 'features')\n",
    "train_vector = vectorAssembler.transform(df_clean)\n",
    "\n",
    "splits = train_vector.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "val = splits[1]\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='price', maxIter=100, regParam=0.8, elasticNetParam=0.1)\n",
    "#rfr= RandomForestRegressor(featuresCol = 'features', labelCol = 'price', maxDepth = 3)\n",
    "\n",
    "###################################################\n",
    "###                  Training                   ###\n",
    "###################################################\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "lr_predictions = lr_model.transform(val)\n",
    "#lr_predictions.select(\"prediction\",\"price\").show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "###            Streaming Preparation            ###\n",
    "###################################################\n",
    "kafkaServer='172.25.27.157:9092'\n",
    "\n",
    "# Kafka Consumer (Topic: streaming-bd)\n",
    "consumer = KafkaConsumer(\n",
    "    'streaming-bd',\n",
    "    bootstrap_servers=kafkaServer,\n",
    "    auto_offset_reset='earliest'\n",
    ")\n",
    "\n",
    "def serializer(message):\n",
    "    return json.dumps(message).encode('utf-8')\n",
    "\n",
    "# Kafka Producer (Topic: streaming-feedback)\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=kafkaServer,\n",
    "    value_serializer=serializer\n",
    ")\n",
    "\n",
    "###################################################\n",
    "###               Streaming Loop                ###\n",
    "###################################################\n",
    "for message in consumer:\n",
    "    streaming_data = json.loads(message.value)\n",
    "    data_normalized = pd.json_normalize(json.loads(message.value))\n",
    "    new_data = pd.DataFrame.from_dict(data_normalized)\n",
    "    \n",
    "    if 'id' in new_data.columns: \n",
    "        id = new_data.iloc[:,0].to_string(index=False)\n",
    "        atual_price = new_data.iloc[:,2].to_string(index=False)\n",
    "\n",
    "        sparkDF=spark.createDataFrame(new_data) \n",
    "\n",
    "        spark_clean = Pipeline(stages=[ColumnDropper(to_remove_col_names), ColumnTransformer()]).fit(sparkDF).transform(sparkDF)\n",
    "        spark_clean = spark_clean.drop('id')\n",
    "\n",
    "        train_vector = vectorAssembler.transform(spark_clean)\n",
    "\n",
    "        predPrice = lr_model.transform(train_vector)\n",
    "        \n",
    "        pred = predPrice.collect()[0][10]\n",
    "        pred = format(np.abs(pred), '.1f')\n",
    "\n",
    "        message = 'ID: ' + id\n",
    "        \n",
    "        if float(pred) > float(atual_price):\n",
    "            message += ' has a Good Price!'\n",
    "        else: \n",
    "            message += ' has a Bad Price!'\n",
    "        \n",
    "        message += ' House price: ' + atual_price + ' | Predition: ' + pred\n",
    "        print(message)\n",
    "        producer.send('streaming-feedback-bd', message)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df8f8261e415d1cd982fd9b77cef1d0f03bb069bb553091b78165945112d252a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
